{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import helper as hp\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import pickle\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import sys\n",
    "#sys.path.append('/home/cesar/anaconda2/lib/python2.7/site-packages/cv2.so')\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%run ./TrainAndTest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Path to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To begin the translation is made only with a small text from english to spanish, since the training might take days even weeks using a real dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_path = 'small_vocab_en'\n",
    "target_path = 'small_vocab_fr'\n",
    "#Padding since not all senteces will have the same size, EOS is the end of sentence\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3}\n",
    "\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_load(path):\n",
    "    files = os.path.join(path)\n",
    "    files = files.encode('utf-8')\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Loading the two small texts\n",
    "input_file = data_load(input_path)\n",
    "target_file = data_load(target_path)\n",
    "#spanish_file = spanish_file.encode('utf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10135742\n"
     ]
    }
   ],
   "source": [
    "x = len(target_file)\n",
    "print(x)\n",
    "x = int(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n",
      "la chaux est son moins aimé des fruits , mais la banane est mon moins aimé.\n",
      "il a vu un vieux camion jaune .\n",
      "inde est pluvieux en juin , et il est parfois chaud en novembre .\n",
      "ce chat était mon a\n"
     ]
    }
   ],
   "source": [
    "print(target_file[:1000])\n",
    "#eng_file = hp.load_file(input_file[:x])\n",
    "#spanish_file = hp.load_file(target_file[:x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "the lime is her least liked fruit , but the banana is my least liked .\n",
      "he saw a old yellow truck .\n",
      "india is rainy during june , and it is sometimes warm in november .\n",
      "that cat was my most loved animal .\n",
      "he dislikes grapefruit , limes , and lem\n"
     ]
    }
   ],
   "source": [
    "print(input_file[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Counting number of unique words and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_words_inp = len({word: None for word in input_file.split()})\n",
    "unique_words_tg = len({word: None for word in target_file.split()})\n",
    "#words_inp = len({word:+1 for word in input_file.split()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in English is :227 and Spanish is :355\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique words in English is :{} and Spanish is :{}'.format(unique_words_inp, unique_words_tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences_inp = input_file.split('\\n')\n",
    "sentences_tg = target_file.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in English is: 137861\n",
      "Number of sentences in Spanish is: 137861\n"
     ]
    }
   ],
   "source": [
    "print('Number of sentences in English is: {}'. format(len(sentences_inp)))\n",
    "print('Number of sentences in Spanish is: {}'. format(len(sentences_tg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "words_target = [len(sentence.split()) for sentence in sentences_tg]\n",
    "words_input = [len(sentence.split()) for sentence in sentences_inp]\n",
    "avg_words_inp = (np.average(words_target))\n",
    "avg_words_tg = (np.average(words_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in English in a sentence 14.2266123124\n",
      "Average number of words in Spanish in a sentence 13.2252776347\n"
     ]
    }
   ],
   "source": [
    "#number of words and average of words\n",
    "\n",
    "print('Average number of words in English in a sentence {}'.format(avg_words_inp))\n",
    "print('Average number of words in Spanish in a sentence {}'.format(avg_words_tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence in Spanish 17\n",
      "Longest sentence in English 23\n"
     ]
    }
   ],
   "source": [
    "print('Longest sentence in Spanish {}'. format(max(words_input)))\n",
    "print('Longest sentence in English {}'. format(max(words_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Stats for words in English"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "stats_inp = pd.DataFrame(data=words_input, columns=['words'])\n",
    "stats_target = pd.DataFrame(data=words_target, columns=['words'])\n",
    "stats_inp.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Stats for words in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-574a79d85abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stats_target' is not defined"
     ]
    }
   ],
   "source": [
    "stats_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(xfile):\n",
    "        #split text file without repetition\n",
    "        vocab = set(xfile.split())\n",
    "        \n",
    "        #starting our table with CODES created on the second shell of this script, with PAD, EOS, etc\n",
    "        \n",
    "        vocab_int = copy.copy(CODES)\n",
    "        for key, value in enumerate(vocab, len(CODES)):\n",
    "            vocab_int[value] = key\n",
    "            \n",
    "        #We do the inverse process now, swapping keys and values   \n",
    "        int_to_vocab = {key:value for value, key in vocab_int.items()} \n",
    "        return vocab_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data_save(input_path, target_path, text_ids):\n",
    "        #loading files into variables\n",
    "        input_text = data_load(input_path)\n",
    "        target_text = data_load(target_path)\n",
    "        \n",
    "        #changing text files to low case\n",
    "        input_text = input_text.lower()\n",
    "        target_text = target_text.lower()\n",
    "        \n",
    "        #creating lookup table, each word will be represented by a number the two variables returned\n",
    "        #represent a way to check the 'id' of each word, similar to a dic in python (key, value)\n",
    "        input_vocab_to_int, int_input_to_vocab = create_lookup_tables(input_text)\n",
    "        target_vocab_to_int, int_target_to_vocab = create_lookup_tables(target_text)\n",
    "        \n",
    "        input_text, target_text = text_to_ids(input_text, target_text, input_vocab_to_int, target_vocab_to_int)\n",
    "        \n",
    "        \n",
    "        ##Saving Data\n",
    "        \n",
    "        pickle.dump(((input_text, target_text), \n",
    "                     (input_vocab_to_int, target_vocab_to_int), \n",
    "                     (int_input_to_vocab, int_target_to_vocab)), open('preprocess_data.p', 'wb'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(input_txt, target_txt, input_vocab, target_vocab):\n",
    "    \n",
    "    input_text_id = [[input_vocab[word] for word in sentence.split()] for sentence in input_txt.split('\\n')]\n",
    "    target_text_id = [[target_vocab[word] for word in sentence.split()] for \n",
    "                     sentence in target_txt.split('\\n')]\n",
    "    \n",
    "    #in case of not having EOS at the end of sentence add it\n",
    "    for i in target_text_id:\n",
    "        if i and i[-1] != target_vocab['<EOS>']:\n",
    "            i += [target_vocab['<EOS>']]\n",
    "    \n",
    "    return input_text_id, target_text_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    return pickle.load(open('preprocess_data.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_par(par):\n",
    "    pickle.dump(par, open('par.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_par():\n",
    "    return pickle.load(open('par.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preprocess_data_save(input_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(input_int, target_int), (source_vocab_int, target_vocab_int), _ = preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Building Neural Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    inputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name='inputs')\n",
    "    target = tf.placeholder(dtype=tf.int32, shape=[None, None], name='target')\n",
    "    learn_rate = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob') #probability that each element is kept\n",
    "\n",
    "    return inputs, target, learn_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##Decoding Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoding_input(target_data, target_vocab_int, batch_size):\n",
    "    \n",
    "    target_batches = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    decoder_input = tf.concat([tf.fill([batch_size, 1], target_vocab_int['<GO>']), target_batches], 1)\n",
    "    \n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encoding(rnn_input, rnn_size, num_layers, keep_prob):\n",
    "    \n",
    "    #encoder_cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "    encoder_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    _, encoder_state = tf.nn.dynamic_rnn(encoder_cell, rnn_input, dtype=tf.float32)\n",
    "    return encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decoder Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoder_logits(encoder_state, decoder_cell, decoder_embedded_input, seq_len, decoding_scope,\n",
    "                  output_layer, keep_prob):\n",
    "    \n",
    "    #train_decoder = tf.contrib.legacy_seq2seq.dynamic_rnn_decoder(encoder_state)\n",
    "    #contrib/seq2seq/python/ops/decoder_fn\n",
    "    \n",
    "    train_decoder = tf.contrib.seq2seq.simple_decoder_fn_train(encoder_state)\n",
    "    train_pred, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell, train_decoder, decoder_embedded_input,\n",
    "                                                             seq_len, scope=decoding_scope)\n",
    "    \n",
    "    train_logits = output_layer(train_pred)\n",
    "    train_logits = tf.nn.dropout(train_logits, keep_prob)\n",
    "    \n",
    "    return train_logits\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoder_layer_logits(encoder_state, decoder_cell, decoder_embedded_input, seq_len, decoding_scope,\n",
    "                  output_layer, keep_prob):\n",
    "    \n",
    "    decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "    decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_embedded_input,\n",
    "\n",
    "    initial_state=encoder_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",)\n",
    "    \n",
    "    decoder_logits = tf.contrib.layers.linear(decoder_outputs, seq_len)\n",
    "    decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', '_allowed_symbols', 'attention_decoder_fn_inference', 'attention_decoder_fn_train', 'dynamic_rnn_decoder', 'prepare_attention', 'sequence_loss', 'simple_decoder_fn_inference', 'simple_decoder_fn_train']\n"
     ]
    }
   ],
   "source": [
    "tf.__version__\n",
    "print(dir(tf.contrib.seq2seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decoding Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer_inference(encoder_state, decoder_cell, decoder_embeddings, start_seq_id, end_seq_id, \n",
    "                   maximum_len, vocab_size, decoding_scope, output_layer, prob):\n",
    "    \n",
    "    inference_decoder = tf.contrib.seq2seq.simple_decoder_fn_inference(output_layer, encoder_state,\n",
    "                                                                       decoder_embeddings, start_seq_id, end_seq_id,\n",
    "                                                                       maximum_len - 1, vocab_size)\n",
    "    inference_logits, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell, inference_decoder,\n",
    "                                                                    scope=decoding_scope)\n",
    "    \n",
    "    inference_logits = tf.nn.dropout(inference_logits, prob)\n",
    "    return inference_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the Decoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(decoder_embedded_input, decoder_embeddings, encoder_state, vocab_size, \n",
    "                   seq_len, rnn_size, num_layers, target_vocab_int, prob):\n",
    "    \n",
    "    #decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "    decoder_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    #decoder_cell_inf = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size) for layer in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        output_layer = lambda x:tf.contrib.layers.fully_connected(x, vocab_size, None, scope=decoding_scope)\n",
    "        \n",
    "        train_logits = decoder_logits(encoder_state, decoder_cell, decoder_embedded_input, \n",
    "                                            seq_len, decoding_scope, output_layer, prob)\n",
    "   \n",
    "    with tf.variable_scope(\"decoding\", reuse=True) as decoding_scope_inf:\n",
    "        decoding_scope.reuse_variables()\n",
    "        inference_logits = decoding_layer_inference(encoder_state, decoder_cell, decoder_embeddings, \n",
    "                                                    target_vocab_int['<GO>'], target_vocab_int['<EOS>'], seq_len,\n",
    "                                                   vocab_size, decoding_scope, output_layer, prob)\n",
    "    return train_logits, inference_logits\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size, seq_len, input_vocab_size, target_vocab_size, \n",
    "                  encoder_embedding_size, decoder_embedding_size, rnn_size, num_layers, target_vocab_int):\n",
    "    \n",
    "    \n",
    "    #Encoder Embedding\n",
    "    encoder_embedding_input = tf.contrib.layers.embed_sequence(input_data, input_vocab_size, encoder_embedding_size)\n",
    "    encoding_state = encoding(encoder_embedding_input, rnn_size, num_layers, keep_prob)\n",
    "    processed_target_data = decoding_input(target_data, target_vocab_int, batch_size)\n",
    "    \n",
    "    #Decoding Embedding\n",
    "    decoder_embedding = tf.Variable(tf.random_uniform([target_vocab_size, decoder_embedding_size]))\n",
    "    decoder_embed_input = tf.nn.embedding_lookup(decoder_embedding, processed_target_data)\n",
    "    \n",
    "    train_logits, inference_logits = decoding_layer(decoder_embed_input, decoder_embedding, encoding_state,\n",
    "                                                    target_vocab_size, seq_len, rnn_size, num_layers,\n",
    "                                                    target_vocab_int, keep_prob)\n",
    "    \n",
    "    return train_logits, inference_logits\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 256\n",
    "rnn_size = 75\n",
    "num_layers = 2\n",
    "encoding_embedding_size = 128\n",
    "decoding_embedding_size = 128\n",
    "\n",
    "learning_rate = 0.005\n",
    "keep_probability = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#_, (source_vocab_int, target_vocab_int),  (source_int_to_vocab, target_int_to_vocab) = preprocess()\n",
    "#print(target_int_to_vocab[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/dev'\n",
    "(input_int, target_int), (input_vocab_int, target_vocab_int), _ = preprocess()\n",
    "longest_seq_input = max([len(seq) for seq in input_int])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr,  keep_prob = model()\n",
    "    seq_len = tf.placeholder_with_default(longest_seq_input, None, name='seq_len')\n",
    "    input_shape = tf.shape(input_data)\n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]), targets, keep_prob, batch_size, seq_len,\n",
    "                                                             len(input_vocab_int), len(target_vocab_int), \n",
    "                                                             encoding_embedding_size, decoding_embedding_size, \n",
    "                                                             rnn_size, num_layers, target_vocab_int)\n",
    "    tf.identity(inference_logits, 'logits')\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        #loss\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(train_logits, targets, tf.ones([input_shape[0], seq_len]))\n",
    "        train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        #optimizer = tf.train.AdamOptimizer(lr)\n",
    "        #gradients = optimizer.compute_gradients(loss)\n",
    "        #gradients_ = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        #train_op = optimizer_apply_gradients(gradients_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_accuracy(target, logits):\n",
    "    x = target.shape[1]\n",
    "    y = logits.shape[1]\n",
    "    longest_seq = max(x, y)\n",
    "    if longest_seq - x:\n",
    "        target = np.pad(target, [(0,0), (0, longest_seq - x)], 'constant')\n",
    "    if longest_seq - y:\n",
    "        logits = np.pad(logits, [(0,0), (0, longest_seq - y), (0,0)], 'constant')\n",
    "    return np.mean(np.equal(target, np.argmax(logits, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/cesar/home/Desktop/Final_NN/logs\"\n",
    "#tf.scalar_summary(\"logits\", logits)\n",
    "#summary_op = tf.merge_all_summaries()\n",
    "\n",
    "#tf.summary.histogram(\"logits\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/538 - Train Accuracy:  0.234, Validation Accuracy:  0.316, Loss:  5.872\n",
      "Epoch   0 Batch  100/538 - Train Accuracy:  0.418, Validation Accuracy:  0.461, Loss:  3.439\n",
      "Epoch   0 Batch  200/538 - Train Accuracy:  0.546, Validation Accuracy:  0.562, Loss:  3.122\n",
      "Epoch   0 Batch  300/538 - Train Accuracy:  0.640, Validation Accuracy:  0.634, Loss:  2.953\n",
      "Epoch   0 Batch  400/538 - Train Accuracy:  0.675, Validation Accuracy:  0.675, Loss:  2.994\n",
      "Epoch   0 Batch  500/538 - Train Accuracy:  0.755, Validation Accuracy:  0.718, Loss:  2.850\n",
      "Epoch   1 Batch    0/538 - Train Accuracy:  0.750, Validation Accuracy:  0.727, Loss:  2.871\n",
      "Epoch   1 Batch  100/538 - Train Accuracy:  0.796, Validation Accuracy:  0.799, Loss:  2.775\n",
      "Epoch   1 Batch  200/538 - Train Accuracy:  0.853, Validation Accuracy:  0.839, Loss:  2.743\n",
      "Epoch   1 Batch  300/538 - Train Accuracy:  0.865, Validation Accuracy:  0.847, Loss:  2.736\n",
      "Epoch   1 Batch  400/538 - Train Accuracy:  0.879, Validation Accuracy:  0.869, Loss:  2.656\n",
      "Epoch   1 Batch  500/538 - Train Accuracy:  0.921, Validation Accuracy:  0.886, Loss:  2.690\n",
      "Epoch   2 Batch    0/538 - Train Accuracy:  0.894, Validation Accuracy:  0.906, Loss:  2.698\n",
      "Epoch   2 Batch  100/538 - Train Accuracy:  0.913, Validation Accuracy:  0.901, Loss:  2.685\n",
      "Epoch   2 Batch  200/538 - Train Accuracy:  0.928, Validation Accuracy:  0.898, Loss:  2.714\n",
      "Epoch   2 Batch  300/538 - Train Accuracy:  0.913, Validation Accuracy:  0.921, Loss:  2.602\n",
      "Epoch   2 Batch  400/538 - Train Accuracy:  0.928, Validation Accuracy:  0.906, Loss:  2.650\n",
      "Epoch   2 Batch  500/538 - Train Accuracy:  0.944, Validation Accuracy:  0.919, Loss:  2.617\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "source_train = input_int[batch_size:]\n",
    "target_train = target_int[batch_size:]\n",
    "\n",
    "source_val = hp.pad_batch(input_int[:batch_size])\n",
    "target_val = hp.pad_batch(target_int[:batch_size])\n",
    "#test_writer = tf.histogram_summary(\"loss\", loss)\n",
    "#writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (source_batch, target_batch) in enumerate(hp.batch_data(source_train,\n",
    "                                                                               target_train, batch_size)):\n",
    "            \n",
    "            start = time.time()\n",
    "            _, loss_ = sess.run([train_op, loss], {input_data: source_batch, targets: target_batch, lr:learning_rate,\n",
    "                                                 seq_len: target_batch.shape[1], keep_prob: keep_probability})\n",
    "            batch_train_logits = sess.run(inference_logits, {input_data:source_batch, keep_prob:1.0})\n",
    "            batch_valid_logits = sess.run(inference_logits, {input_data:source_val, keep_prob:1.0})\n",
    "            \n",
    "            #test_writer.add_summary(loss, batch)\n",
    "            \n",
    "            \n",
    "            train = get_accuracy(target_batch, batch_train_logits)\n",
    "            #tf.summary.histogram(\"logits\", train)\n",
    "            valid = get_accuracy(np.array(target_val), batch_valid_logits)\n",
    "            end = time.time()\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "                  .format(epoch, batch, len(input_int) // batch_size, train, valid, loss_))\n",
    "            loss_hist.append(loss_)\n",
    "            #writer.add_summary(train_logits, epoch * batch_count + i)\n",
    "            \n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e68692b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()\n",
    "#print(loss_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seq_to_seq(sent, vocab_int):\n",
    "    word_id = [vocab_int.get(word, vocab_int['<UNK>']) for word in sent.split()]\n",
    "    return word_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    \"\"\"\n",
    "    Save parameters to file\n",
    "    \"\"\"\n",
    "    pickle.dump(params, open('params.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_params():\n",
    "    \"\"\"\n",
    "    Load parameters from file\n",
    "    \"\"\"\n",
    "    return pickle.load(open('params.p', mode='rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, (source_vocab_int, target_vocab_int),  (source_int_to_vocab, target_int_to_vocab) = preprocess()\n",
    "#load_path = load_par()\n",
    "load_path = load_params()\n",
    "\n",
    "#(input_int, target_int), (source_vocab_int, target_vocab_int), _ = preprocess()\n",
    "#(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(target_int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ./traininig.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JANUARY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traininig as tt\n",
    "x = tt.func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "january\n"
     ]
    }
   ],
   "source": [
    "x = x.lower()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "Words ids:       [54]\n",
      "English words:   ['january']\n",
      "\n",
      "Prediction\n",
      "Words ids:       [133, 42, 257, 1]\n",
      "French words:   ['en', 'f\\xc3\\xa9vrier', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "translate = 'january .'\n",
    "#import ptf.import_graph_def.\n",
    "translate = seq_to_seq(x, source_vocab_int)\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "    \n",
    "    input_data = loaded_graph.get_tensor_by_name('inputs:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    \n",
    "    translate_logits = sess.run(logits, {input_data: [translate], keep_prob: 1.0})[0]\n",
    "    \n",
    "print('Input')\n",
    "print('Words ids:       {}'. format([ids for ids in translate]))\n",
    "print('English words:   {}'. format([source_int_to_vocab[i] for i in translate]))\n",
    "\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('Words ids:       {}'. format([i for i in np.argmax(translate_logits, 1)]))\n",
    "print('French words:   {}'. format([target_int_to_vocab[i] for i in np.argmax(translate_logits, 1)]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import get_str as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import TrainAndTest as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%run ./TrainAndTest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
